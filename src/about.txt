Machines have learned to recognize faces, drive cars, play Go, create art, and even smell. But what about learning how to listen to music? Listening to and enjoying music is an experience that is uniquely human. Nothing but vibrations in the air, music can be both incredibly simple and infinitely complex at the same time.

Can a machine identify, isolate, and extract the emotional response we feel when listening to music? Which emotions can be extracted from music? Can humans even do this? <a target="_blank" href="https://www.frontiersin.org/research-topics/4749/music-and-the-functions-of-the-brain-arousal-emotions-and-pleasure">Empirical</a> <a target="_blank" href="https://www.ncbi.nlm.nih.gov/pubmed/23769678">research</a> <a target="_blank" href="http://uu.diva-portal.org/smash/get/diva2:410669/FULLTEXT01.pdf">suggests</a> that even within a single person, there are many factors such as setting, current temperament, recent events, or even present mindfulness that may influence the emotional response to the same song.

As both a data scientist and a passionate consumer of all types of music, I was very curious about the answer to these questions and wanted to see if deep learning was powerful enough to capture this relationship. To do this, I employed the help of Spotify, completing nearly half a billion searches over the course of several months — using user-generated playlists to crowdsource our collective emotional experience of music. This data was used to come up with 500 different emotions or moods that can be experienced when listening to music. This was later consolidated to roughly 250 — of which you can explore on this app.

As you’re exploring the data, keep in mind that this is what the majority of people feel when listening to a particular song. Millions of playlists have been analyzed using the latest breakthroughs in natural language processing, building up a list of tracks that repeatedly appear for a given emotion. The more often a track appeared, the more likely it was included in the final algorithm. While not all results are perfect and there are some biases in the data (be sure to read the forthcoming blog post outlining the technical details of the project), it is truly incredible to see not only the ability of an algorithm to learn from audio data alone, but how we as humans can reach a consensus on how music makes us feel.

In Latin, "sentire" means both "to listen" and "to feel" -- something that, in my opinion, sums up perfectly the musical experience and this project. This was truly a labor of love and I hope you enjoy exploring the data as much as I did creating it.



